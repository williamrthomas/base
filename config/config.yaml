llm:
  api_provider: "openrouter" # or "openai", "anthropic", etc.
  base_url: "https://openrouter.ai/api/v1/chat/completions" #  Make sure to change this if you are using a different provider
  api_key_env_var: "OPENROUTER_API_KEY" # or "ANTHROPIC_API_KEY", "OPENAI_API_KEY", etc.
  model: "anthropic/claude-3.5-sonnet" # Default model
  max_tokens: 8192  # Default max tokens
  temperature: 0.7 # Default temperature
  requests_cache_seconds: 86400 # Cache enabled for 1 day by default
